{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002c2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baffffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5141c867de4e93a73bc31f9f9fe7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5af28",
   "metadata": {},
   "source": [
    "Load models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac11d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM2-360M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48190b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888930ec29814184a2752729da876710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dcca05b0b04567a3eaf2ee5ffcf52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/524 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa120f232ca4333829fadf6f9e6625d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8ecc7e7c354c7aa39a76bc25756a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/524 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the bom dataset\n",
    "bom_dataset = load_dataset(\"burman-ai/The-Book-of-Mormon\")\n",
    "# The dataset only comes with a train split, so let's add a test set\n",
    "bom_dataset = bom_dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "bom_dataset_train = bom_dataset[\"train\"]\n",
    "bom_dataset_test = bom_dataset[\"test\"]\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def bom_tokenize_function(examples):\n",
    "    return tokenizer(examples[\"scripture_text\"], truncation=True, padding=\"max_length\", max_length=2048)\n",
    "\n",
    "bom_dataset_train = bom_dataset_train.map(bom_tokenize_function, batched=True)\n",
    "bom_dataset_test = bom_dataset_test.map(bom_tokenize_function, batched=True)\n",
    "\n",
    "bom_dataset_train = bom_dataset_train.remove_columns([col for col in bom_dataset_train.column_names if col not in [\"input_ids\", \"attention_mask\"]])\n",
    "bom_dataset_test = bom_dataset_test.remove_columns([col for col in bom_dataset_test.column_names if col not in [\"input_ids\", \"attention_mask\"]])\n",
    "\n",
    "# we add a labels field that is identical to input_ids for causal language modeling\n",
    "# HF automatically shifts the labels over one position when computing the loss\n",
    "bom_dataset_train = bom_dataset_train.map(\n",
    "    lambda examples: {\"labels\": examples[\"input_ids\"]},\n",
    "    batched=True\n",
    ")\n",
    "bom_dataset_test = bom_dataset_test.map(\n",
    "    lambda examples: {\"labels\": examples[\"input_ids\"]},\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0292470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e61f4e388ac44809763999f9a30dcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24137416f1f946f58fa6b64e61429b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff493a843b14bbd948552b387a3ced7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c26032ccd684528a49db405a9279d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the arxiv dataset\n",
    "arxiv_dataset = load_dataset(\"gfissore/arxiv-abstracts-2021\")\n",
    "# This dataset has 2 million rows; let's select a random subset of 5k rows to match the other dataset\n",
    "arxiv_dataset = arxiv_dataset[\"train\"].shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# The dataset only comes with a train split, so let's add a test set\n",
    "arxiv_dataset = arxiv_dataset.train_test_split(test_size=0.1)\n",
    "arxiv_dataset_train = arxiv_dataset[\"train\"]\n",
    "arxiv_dataset_test = arxiv_dataset[\"test\"]\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def arxiv_tokenize_function(examples):\n",
    "    return tokenizer(examples[\"abstract\"], truncation=True, padding=\"max_length\", max_length=2048)\n",
    "\n",
    "arxiv_dataset_train = arxiv_dataset_train.map(arxiv_tokenize_function, batched=True)\n",
    "arxiv_dataset_test = arxiv_dataset_test.map(arxiv_tokenize_function, batched=True)\n",
    "\n",
    "arxiv_dataset_train = arxiv_dataset_train.remove_columns([col for col in arxiv_dataset_train.column_names if col not in [\"input_ids\", \"attention_mask\"]])\n",
    "arxiv_dataset_test = arxiv_dataset_test.remove_columns([col for col in arxiv_dataset_test.column_names if col not in [\"input_ids\", \"attention_mask\"]])\n",
    "\n",
    "# we add a labels field that is identical to input_ids for causal language modeling\n",
    "# HF automatically shifts the labels over one position when computing the loss\n",
    "arxiv_dataset_train = arxiv_dataset_train.map(\n",
    "    lambda examples: {\"labels\": examples[\"input_ids\"]},\n",
    "    batched=True\n",
    ")\n",
    "arxiv_dataset_test = arxiv_dataset_test.map(\n",
    "    lambda examples: {\"labels\": examples[\"input_ids\"]},\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d8eb2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f85a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lora config\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r = 64,\n",
    "    lora_alpha = 128,\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b89939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model and add LoRA adapters\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3df680fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 34,734,080 || all params: 396,555,200 || trainable%: 8.7590\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e056179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class SampleGenerationCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, sample_prompt, max_new_tokens=50):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_prompt = sample_prompt\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def generate_sample(self, model):\n",
    "        model.eval()\n",
    "        inputs = self.tokenizer(self.sample_prompt, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=self.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(\"\\nSample output:\\n\", text)\n",
    "        model.train()\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(f\"\\n=== Starting training ===\")\n",
    "        self.generate_sample(kwargs[\"model\"])\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None and \"loss\" in logs:\n",
    "            print(f\"\\nStep {state.global_step} | Loss: {logs['loss']:.4f}\")\n",
    "            self.generate_sample(kwargs[\"model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bedf9",
   "metadata": {},
   "source": [
    "Training bom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61bc7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bom-lora\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate = 2e-4,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=20,\n",
    "    logging_steps=20,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfde278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3602321636.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=bom_dataset_train,\n",
    "    eval_dataset=bom_dataset_test,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[SampleGenerationCallback(tokenizer, sample_prompt=\"And it came to\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbd7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjay-orten\u001b[0m (\u001b[33mjay-o\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251121_200217-1vw6t55k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jay-o/huggingface/runs/1vw6t55k' target=\"_blank\">exalted-aardvark-13</a></strong> to <a href='https://wandb.ai/jay-o/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jay-o/huggingface' target=\"_blank\">https://wandb.ai/jay-o/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jay-o/huggingface/runs/1vw6t55k' target=\"_blank\">https://wandb.ai/jay-o/huggingface/runs/1vw6t55k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample output:\n",
      " And it came to pass that when Jesus was on the mount of Olives, the first day of the feast, that he taught the people, and they were astonished at his doctrine.\n",
      "\n",
      "\n",
      "The next day, when Jesus was walking by the sea of Galilee,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='295' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [295/295 12:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.060500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 20 | Loss: 2.1814\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that after the Lord had made the world, the Lord sent forth his spirit into the world, and the Lord made the world.\n",
      "\n",
      "Step 40 | Loss: 0.0668\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the sons of the women, the sons of the women, did not fear to go forth and to seek for the king, and to seek for the land; and they went forth and came in unto the land, and they did seek for\n",
      "\n",
      "Step 60 | Loss: 0.0625\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the Lord God commanded that the people should be numbered, and that they should be counted in all their tribes, and their fathers' houses, and their houses, and their lands, and their cities, and their towns, and their villages,\n",
      "\n",
      "Step 80 | Loss: 0.0603\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the people of Judah were filled with anger against their brethren the children of Ammon.\n",
      "\n",
      "Step 100 | Loss: 0.0611\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that there were many of them who were of the priests of the Lord, and they were not of the priests of the Lamanites.\n",
      "\n",
      "Step 120 | Loss: 0.0572\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the Nephites, who had been left in the land, and the Lamanites, who were left in the land, and all the Nephites, who were left in the land, were not able to come together to make war against\n",
      "\n",
      "Step 140 | Loss: 0.0565\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the people of Nephi began to be numbered in the land of Zarahemla.\n",
      "\n",
      "Step 160 | Loss: 0.0605\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that when the people had assembled, and had taken counsel together, that they had made the following covenant:\n",
      "\n",
      "Step 180 | Loss: 0.0580\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that when the king and all his people had assembled unto him again, he began to speak unto them concerning their enemies, saying: Behold, I have heard of a people which have come into our land, and they have taken possession of our\n",
      "\n",
      "Step 200 | Loss: 0.0598\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the Lord said unto him: And it came to pass that it was the day of the beginning of the year; and the Lord said unto me: And behold, there was a great famine throughout the land.\n",
      "\n",
      "Step 220 | Loss: 0.0589\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that he began to labor to make the things of the world, and to gather together the fruits of the earth; yea, even to gather in the fruits of the earth, and to gather in the fruits of the earth, and to gather\n",
      "\n",
      "Step 240 | Loss: 0.0579\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that when Alma had sent forth his army to pursue the Lamanites, behold, they had marched on from the wilderness until they came to the borders of the land of Zarahemla.\n",
      "\n",
      "Step 260 | Loss: 0.0556\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that he did not believe that the Lamanites had been destroyed, but he did believe that the Lamanites would not be destroyed, for he was not of the people of Nephi, but he was a stranger, and he was a\n",
      "\n",
      "Step 280 | Loss: 0.0563\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the Lord commanded that they should go forth, and that they should gather all the corn and all the wheat, and all the wheat in the field, and all the barley, and all the barley in the field, and all the wheat in\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=295, training_loss=0.2031243421263614, metrics={'train_runtime': 788.9198, 'train_samples_per_second': 5.978, 'train_steps_per_second': 0.374, 'total_flos': 2.024602244481024e+16, 'train_loss': 0.2031243421263614, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e8463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"final_lora_adapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb416c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f91fc5ed4847c0a1d1100642baa9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82da54bd332546fdaa9efd36b7b5b05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f953e6c2af3c42e2bcdb5c0d1ac60b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   0%|          | 29.7kB /  139MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/royal42/final_bom_lora_adapter/commit/50eba2b215fa9d2c62b24e65f27db3bba3da1ea9', commit_message='Upload model', commit_description='', oid='50eba2b215fa9d2c62b24e65f27db3bba3da1ea9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/royal42/final_bom_lora_adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='royal42/final_bom_lora_adapter'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"royal42/final_bom_lora_adapter\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36675e01",
   "metadata": {},
   "source": [
    "Training code model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "820680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./arxiv-lora\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate = 2e-4,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=20,\n",
    "    logging_steps=20,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e00e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1894280165.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=arxiv_dataset_train,\n",
    "    eval_dataset=arxiv_dataset_test,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[SampleGenerationCallback(tokenizer, sample_prompt=\"And it came to\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df6ad4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting training ===\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that when Jesus was on the mount of Olives, the first day of the feast, that he taught the people, and they were astonished at his doctrine.\n",
      "\n",
      "\n",
      "The next day, when Jesus was walking by the sea of Galilee,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [282/282 12:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.270200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.265900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.271500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 20 | Loss: 2.5792\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that after the Lord had made the world, the Lord sent out his spirit and made all things. And it came to pass, that after the Lord had made all things, the Lord sent out his spirit and made all things. And it came\n",
      "\n",
      "Step 40 | Loss: 0.2841\n",
      "\n",
      "Sample output:\n",
      " And it came to pass, that after these things had been fulfilled, Jesus went down to the sea of Tiberias, and there was casting a net into the sea, and he drew up the net full of young fishes, and he let it down again into the sea\n",
      "\n",
      "Step 60 | Loss: 0.2810\n",
      "\n",
      "Sample output:\n",
      " And it came to pass, that when they had been in the camp for a long time, there came into the camp a man that was a prophet, who spoke as the Spirit of God had appointed him; and the Lord said to him, \"Go and tell the\n",
      "\n",
      "Step 80 | Loss: 0.2702\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that the great King of the East, who was called the Lord of Hosts, came to the city of Jerusalem with a great army, and he had a great army of the kings of the East. And when he had gone to the city\n",
      "\n",
      "Step 100 | Loss: 0.2625\n",
      "\n",
      "Sample output:\n",
      " And it came to a point where we had a lot of problems with the weather and the weather and the weather. And we had a lot of problems with the weather. We had a lot of problems with the weather. And we had a lot of problems with the weather\n",
      "\n",
      "Step 120 | Loss: 0.2780\n",
      "\n",
      "Sample output:\n",
      " And it came to pass, that the Lord God was angry with the man, and slew him; and we have no memory of how he died. But after that the serpent deceived the woman, and she gave birth to a son, and she named him Cain.\n",
      "\n",
      "Step 140 | Loss: 0.2693\n",
      "\n",
      "Sample output:\n",
      " And it came to a head with the \"sophisticated\" and \"advanced\" \n",
      "Israeli regime, who were in a position to do something about the \n",
      "massacre in Gaza. They decided to do nothing.\n",
      "\n",
      "The \"sophisticated\"\n",
      "\n",
      "Step 160 | Loss: 0.2659\n",
      "\n",
      "Sample output:\n",
      " And it came to pass that a certain man had a son, whose name was Ishmael. And he went down to Egypt, and dwelt in the land of Egypt. And he said to his son, \"What shall I do to you, my son, that I\n",
      "\n",
      "Step 180 | Loss: 0.2581\n",
      "\n",
      "Sample output:\n",
      " And it came to pass, that they should build a wall against the people of the land, which was under the hands of the Syrians, and they should fight against the people of the land, and they should build a wall against them, and they should build the\n",
      "\n",
      "Step 200 | Loss: 0.2583\n",
      "\n",
      "Sample output:\n",
      " And it came to pass, that in the days of Elisha the son of Shaphat, in the days of Jehu the son of Omri, in the days of Jeroboam the son of Joash, and in the days of Pekah\n",
      "\n",
      "Step 220 | Loss: 0.2636\n",
      "\n",
      "Sample output:\n",
      " And it came to this, that the Lord Jesus said to the Jews, “If you were of the house of Israel, you would have been looking for the prophet Elijah, to whom the Lord Jesus sent food to eat. But you are not looking for Elijah, but\n",
      "\n",
      "Step 240 | Loss: 0.2513\n",
      "\n",
      "Sample output:\n",
      " And it came to be that, as the war between the Northern and Southern States was at an end, and the country was at peace, the Federal Government was at liberty to dispose of all its property, and to do so as it saw fit. This was, however\n",
      "\n",
      "Step 260 | Loss: 0.2646\n",
      "\n",
      "Sample output:\n",
      " And it came to pass when the days of the Messiah were fulfilled, that the Lord gave unto David the\n",
      "name of \"the King of Israel and of Judah\" (2 Samuel 7:16), and the\n",
      "kingdom of David was confirmed in the land\n",
      "\n",
      "Step 280 | Loss: 0.2715\n",
      "\n",
      "Sample output:\n",
      " And it came to pass when the days of the Feast of Tabernacles were ended, that the LORD spake unto Moses, saying,\n",
      "\n",
      "14And Moses said unto the LORD, Behold, I have brought my people out of Egypt, to possess the land\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=282, training_loss=0.43116534453757266, metrics={'train_runtime': 755.0019, 'train_samples_per_second': 5.96, 'train_steps_per_second': 0.374, 'total_flos': 1.931872370688e+16, 'train_loss': 0.43116534453757266, 'epoch': 1.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36fa2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"final_lora_adapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44ce9659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdcfb8ed9624b34b7e809f412c18230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9bc1f9a1f74903a0fa44159751dda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018963e87f08482cbd21af591cb0c409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   0%|          | 29.7kB /  139MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/royal42/final_arxiv_lora_adapter/commit/72ee4abc0bde098671cf95cbbbb6cdd53ad690f7', commit_message='Upload model', commit_description='', oid='72ee4abc0bde098671cf95cbbbb6cdd53ad690f7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/royal42/final_arxiv_lora_adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='royal42/final_arxiv_lora_adapter'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"royal42/final_arxiv_lora_adapter\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2c76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
